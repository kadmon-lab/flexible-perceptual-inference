{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating data because /home/john/enzyme-of-computation/enzyme/src/mouse_task/north_test.pickle does not exist or try_cached is False\n",
      "task has ITI PM 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bayes ITI_mean = 1 ITI PM = 0, ITI_approx = True, ctx_approx = True, trials_per_block = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2233031/1437734313.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  agent.load_state_dict(torch.load(save_path / str(f'{net_filename}'), map_location=torch.device(device)))\n",
      "<string>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://127.0.0.1:8888/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # GENERATING AND SAVING DATA \n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from enzyme.src.helper import load_pytree, save_pytree\n",
    "import joblib\n",
    "from enzyme import PRJ_ROOT\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "save_path = PRJ_ROOT / str('Data/')\n",
    "device = 'cuda:0'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_data(try_cached=True, config=None, name = \"plotting_data\", load = 'pkl', eps = 5000, mini_eps = 500):\n",
    "    import pickle\n",
    "    path = PRJ_ROOT / str('enzyme/src/mouse_task/' + name + '.pickle')\n",
    "    alt_path = PRJ_ROOT / str('Data/ignore/' + name + '.pickle')\n",
    "    if alt_path.exists():\n",
    "        path = alt_path\n",
    "    if try_cached and (path.exists() or path.with_suffix('').exists()):\n",
    "        if load == \"pkl\":\n",
    "            with open(path, 'rb') as f:\n",
    "               return pickle.load(f)\n",
    "        elif 'tree' in load:\n",
    "            print(f\"loading pytree data from {path.with_suffix('')}\")\n",
    "            return load_pytree(path)\n",
    "        else:\n",
    "            raise ValueError(f\"load argument {load} not recognized\")\n",
    "    else:\n",
    "        \"\"\"\n",
    "        Simulate the data. \n",
    "        \"\"\"\n",
    "        print(f\"generating data because {path} does not exist or try_cached is False\")\n",
    "        # %%\n",
    "        from enzyme.src.main.run_simulation import run_simulation; import torch\n",
    "        from enzyme.src.network.Actor_Critic import Actor_Critic;  \n",
    "        from enzyme.src.mouse_task.mouse_task import mouse_task_; \n",
    "        from enzyme.src.mouse_task.data_structures import cage_data_struct\n",
    "        save_path = PRJ_ROOT / str('Data/')\n",
    "        plotting_data = dict()\n",
    "        \n",
    "        def gen_data(prefix, subnets, N, give_ctx = False, argmax = False, end_nogo = True, ITI_PM = 10,\n",
    "            inp_is_consec = False, use_mini_eps = True, plant = \"random\", plant_prob = 0, PGOs = None, ignore_action = False):\n",
    "            print(f\"task has ITI PM {ITI_PM}\")\n",
    "            inp_dim = 5 + give_ctx\n",
    "            net_filename = prefix + '_net.pth'\n",
    "            if inp_is_consec: \n",
    "                inp = 'raw'\n",
    "            else:\n",
    "                inp = 'one_hot'\n",
    "            loss_params = {'discount' : .995, 'B_val' : .1, 'B_ent': 0, 'decrease_entropy' : False}\n",
    "            network_params = {'inp_dim': inp_dim, 'hid_dim' : N, 'act_dim' : 2, 'device' : device, 'mode' : 'LSTM', 'get_dynamics_of' : 'actor', 'mechanistic': None,\n",
    "                'expansion' : None, 'pavlovian_bias' : False, 'lesion': [], 'handmade': False, 'subnets': subnets, 'RAP' : 0, 'argmax' : argmax, 'exp_ITI': False,\n",
    "                'use_vanilla_torch': False, 'train_recurrent' : True, 'lr_decay': 1, 'skip_storage' : False, 'cost_of_action' : 0}\n",
    "            \n",
    "            optim_params = {'lr' : .0001, 'alpha' : .99, 'eps' : 1e-5, 'weight_decay' : .0, 'momentum' : 0, 'centered' : False}\n",
    "            agent_params = dict(loss_params, **optim_params, **network_params)  \n",
    "            agent = Actor_Critic(**agent_params)\n",
    "            mouse_task_params = {'sim_ID' : 3, 'save_path' : save_path, 'act_dim' : 2, 'exp_mean': 10, 'exp_max': 50,  'W4L': 35, 'ITI_mean' : 15, 'ITI_PM' : ITI_PM,\n",
    "                                 'store_tensors' : False, 'ignore_action' : ignore_action,'prem_dur': 0, 'give_ctx': give_ctx, 'inp_is_consec': inp_is_consec,\n",
    "                                 'plant_type' : plant, 'end_NOGO': end_nogo, 'start_NOGO': False, 'regress_on' : [\"CELL\"], 'max_traj_steps': 40, 'basis_on' : 'output', \n",
    "                                 'plant_prob': plant_prob, 'neg_rew' : 0, 'theta_traj' : None}\n",
    "            manager_params = {'training' : False, 'input': inp, 'skip_first_trial_rew': False, 'device' : device,  'skip_storage': False} \n",
    "            agent.load_state_dict(torch.load(save_path / str(f'{net_filename}'), map_location=torch.device(device)))\n",
    "            mouse_task_params['PGO_range'] = [.1, .2, .3, .4, .5, .6, .7, .8, .9] if PGOs is None else PGOs\n",
    "\n",
    "            mouse_task_params['episodes'] = mini_eps if use_mini_eps else eps \n",
    "            mouse_task_params['num_trials'] = 20\n",
    "            mouse_task_params['exp_min'] = 1 \n",
    "            mouse_task_params['store_tensors'] = True\n",
    "            testing_sim_params = dict(agent_params, **mouse_task_params, **manager_params)\n",
    "            testing = run_simulation(mouse_task_, testing_sim_params, agent, plot_episode = False)\n",
    "            testing.sim.preprocess_data(manager = testing, skip_bayes_full = False)\n",
    "            testing.sim.run_PCA()           \n",
    "            testing.sim.run_regressions(regress_to = 'ground_truth', regress_from = 'STM', get = True)\n",
    "            testing.sim.get_indices(eps_init = 0, full_prep = True, align_on = \"action\", cross_validation = None, til_action = True)        \n",
    "            return testing.sim\n",
    "        \n",
    "        def postprocess_networks(self, agent_name, i, plotting_data):\n",
    "            if i > 0:\n",
    "                agent_name = agent_name + suffix\n",
    "            plotting_data[agent_name] = dict()\n",
    "            agent = plotting_data[agent_name]\n",
    "            append_common_fields(self, agent)\n",
    "            append_common_fields2(self, agent)\n",
    "            del(self)\n",
    "            \n",
    "        def postprocess_bayes(self, agent):\n",
    "            append_common_fields(self, agent)\n",
    "            self.estimate_crossvalidation()\n",
    "            agent[\"10_fold_net_state_acc\"] = self.net_acc\n",
    "            agent[\"10_fold_bayes_state_acc\"] = self.bayes_acc\n",
    "            agent[\"10_fold_bayes_net_state_R2\"] = self.net_bayes_state_R2\n",
    "            agent[\"10_fold_bayes_net_theta_R2\"] = self.net_bayes_theta_R2\n",
    "            agent[\"10_fold_bayes_theta_R2\"] = self.bayes_theta_R2\n",
    "            agent[\"10_fold_net_theta_R2\"] = self.net_theta_R2\n",
    "            del(self)\n",
    "\n",
    "        def append_common_fields(self, agent):\n",
    "            agent[\"PGO_range\"] = self.PGO_range\n",
    "            agent[\"analytical_rew_rate_curves_y_axis\"] =  self.ana_rates\n",
    "            agent[\"analytical_rew_rate_curves_x_axis\"] =  self.ana_xax\n",
    "            agent[\"analytical_rew_rate_points_y_axis\"] =  self.rate_mu\n",
    "            agent[\"analytical_rew_rate_points_x_axis\"] =  self.wait_mu\n",
    "            agent[\"wait_from_switch_per_pgo\"] = self.wait_from_switch\n",
    "            agent[\"trial_vec\"] =  self.trial\n",
    "            agent[\"trial_PGO_vec\"] = self.PGOs            \n",
    "            agent[\"net_wait_from_last_nogo_vec\"] =  self.wait_from_last\n",
    "            agent[\"net_wait_from_last_nogo_per_PGO\"] =  self.wait_PDF_avg\n",
    "            agent[\"behavior_dists_density\"] =  self.wait_PDF\n",
    "            agent[\"behavior_dists_edges\"] =  self.wait_xax\n",
    "            agent[\"analytical_rew_rate_curves_y_axis\"] =  self.ana_rates\n",
    "            agent[\"analytical_rew_rate_curves_x_axis\"] =  self.ana_xax\n",
    "            agent[\"analytical_rew_rate_points_y_axis\"] =  self.rate_mu\n",
    "            agent[\"analytical_rew_rate_points_x_axis\"] =  self.wait_mu\n",
    "            agent[\"wait_from_switch_per_pgo\"] = self.wait_from_switch\n",
    "            agent[\"analytical_optimal_avg_thresh\"] =  self.fixed_max_thresh\n",
    "            agent[\"wait_from_last_nogo_first_trial_from_switch\"] =  self.wait_from_switch[:, 1]\n",
    "            self.get_indices(eps_init = 0, full_prep = True, align_on = \"action\", til_action = True)  \n",
    "            agent[\"step_SAFE_STATE_vec\"] =  self.PSAFE_flat\n",
    "            agent[\"step_PGO_vec\"] =  self.PGO_flat\n",
    "            agent[\"step_trial_vec\"] =  self.trial_flat\n",
    "            agent[\"step_act_vec\"] =  self.cum_acts\n",
    "            agent[\"step_RT_vec\"] =  self.RT_flat\n",
    "\n",
    "            agent[\"step_thresh_RMS_vec\"] = self.flow_thresh_RMS_flat         \n",
    "            agent[\"step_thresh_vec\"] = self.flow_thresh_flat   \n",
    "            agent[\"DV_mu\"] = self.flow_dist_from_opt_mus\n",
    "            agent[\"DV_RMS\"] = self.flow_belief_RMS_mus \n",
    "            agent[\"bayes_wait_from_last_nogo_vec\"] =  self.wait_from_last\n",
    "            agent[\"bayes_wait_from_last_nogo_per_PGO\"] =  self.wait_PDF_avg\n",
    "\n",
    "            agent[\"bayes_state_estimate\"] =  self.flow_belief_flat\n",
    "            agent[\"bayes_PGO_estimate\"] =  self.flow_theta_flat\n",
    "            agent[\"net_state_estimate_CV\"] = self.net_belief_flat\n",
    "            agent[\"net_PGO_estimate_CV\"] = self.net_theta_flat\n",
    "            agent[\"step_SAFE_STATE_CV\"] = self.PSAFE_flat\n",
    "            agent[\"step_stim_CV\"] = self.input_flat[1]\n",
    "            agent[\"step_PGO_CV\"] = self.PGO_flat\n",
    "\n",
    "            agent[\"net_wait_from_last_nogo_vec\"] =  self.wait_from_last\n",
    "            agent[\"action_prob_per_PGO\"] =  self.lick_prob_mus\n",
    "            agent[\"bayes_DV_mu\"] = self.flow_dist_from_opt_mus\n",
    "            agent[\"bayes_DV_RMS\"] = self.flow_belief_RMS_mus \n",
    "            agent[\"net_DV_mu\"] = self.net_dist_from_opt_mus \n",
    "            agent[\"QDIFF_mu\"] = self.QDIFF_mus \n",
    "            agent[\"mu_var_N\"] = self.N_mus \n",
    "            agent[\"bayes_DV\"] = self.flow_dist_from_opt_flat \n",
    "            agent[\"lick_prob_flat\"] = self.lick_prob_flat \n",
    "            agent[\"consec_inds\"] = self.consec_flat \n",
    "            agent[\"ACT_inds\"] = self.cum_acts \n",
    "            agent[\"net_DV\"] = self.Q_flat[1] \n",
    "            agent[\"GO_inds\"] = self.GO_inds \n",
    "            agent[\"PGO_inds_for_heatmap\"] = self.PGO_flat\n",
    "            agent[\"net_DV_est_mu\"] = self.net_DV_est_mus \n",
    "\n",
    "            agent[\"PC_flat\"] = self.PC_flat\n",
    "            agent[\"Q_flat\"] = self.Q_flat[1] \n",
    "            agent[\"GO_flat\"] = self.input_flat[1]\n",
    "            agent[\"pre_act_flat\"] = self.ACTION_inds\n",
    "            agent[\"QDIFF_flat\"] = self.QDIFF_flat \n",
    "            agent[\"STM_flat\"] = self.output_flat\n",
    "            agent[\"safe_flat\"] = self.PSAFE_flat \n",
    "            agent[\"theta_flat\"] = self.PGO_flat \n",
    "            agent[\"bayes_DV_flat\"] = self.flow_dist_from_opt_flat \n",
    "\n",
    "        def append_common_fields2(self, agent):\n",
    "            half = self.max_traj_steps//2\n",
    "            self.get_indices(eps_init = 0, cross_validation = None, full_prep = True, align_on = \"action\")        \n",
    "            agent[\"net_wait_from_last_nogo_per_PGO\"] =  self.wait_PDF_avg    \n",
    "            agent[\"PC1_til_action_per_PGO\"] =  self.PC_mus[0, :, :half+1]\n",
    "            agent[\"PC2_til_action_per_PGO\"] =  self.PC_mus[1, :, :half+1]\n",
    "            agent[\"avg_stim_per_PGO\"] =  self.GO_mus[:, :half+1]\n",
    "            agent[\"PC1_from_action_per_PGO\"] =  self.PC_mus[0, :, half:]\n",
    "            agent[\"PC3_from_action_per_PGO\"] =  self.PC_mus[2, :, half:]\n",
    "            agent[\"avg_stim_per_PGO_from_act\"] =  self.GO_mus[:, half:]\n",
    "            agent[\"PC1_from_safe_per_PGO\"] =  self.PC_mus[0, :, half-2:]\n",
    "            agent[\"PC2_from_safe_per_PGO\"] =  self.PC_mus[1, :, half-2:]\n",
    "            agent[\"PC1_from_safe_per_PGO\"] =  self.PC_mus[0, :, half-2:]\n",
    "            agent[\"PC2_from_safe_per_PGO\"] =  self.PC_mus[1, :, half-2:]\n",
    "\n",
    "            self.get_N_consec_vs_est(get = True)\n",
    "            agent[\"net_PSAFE_vs_N\"] = self.net_safe_est_N\n",
    "            agent[\"net_PSAFE_vs_N_per_PGO\"] = self.net_safe_est_N_per_PGO\n",
    "            agent[\"samples_vs_N_per_PGO\"] = self.samples_N_per_PGO\n",
    "            agent[\"R2_N_per_PGO\"] = self.R2_N_per_PGO\n",
    "\n",
    "            self.run_regressions(regress_to = 'ground_truth', regress_from = 'PCA', get = True)\n",
    "            self.get_indices(eps_init = 0, full_prep = True, align_on = \"action\", til_action = True)        \n",
    "            agent[\"PC_bayes_state\"] =  self.flow_belief_flat\n",
    "            agent[\"PC_bayes_PGO\"] =  self.flow_theta_flat\n",
    "            agent[\"PC_to_state\"] = self.net_belief_flat\n",
    "            agent[\"PC_to_PGO\"] = self.net_theta_flat\n",
    "            agent[\"PC_safe\"] = self.PSAFE_flat\n",
    "            agent[\"PC_input\"] = self.input_flat[1]\n",
    "            agent[\"PC_PGO\"] = self.PGO_flat\n",
    "            agent[\"PC_to_DV_est_mu\"] = self.net_DV_est_mus \n",
    "            agent[\"PFC_to_net_DV_mu\"] = self.net_dist_from_opt_mus \n",
    "\n",
    "\n",
    "            self.run_regressions(regress_to = 'ground_truth', regress_from = 'QDIFF', get = True)\n",
    "            self.get_indices(eps_init = 0, full_prep = True, align_on = \"action\", til_action = True)        \n",
    "            agent[\"QDIFF_bayes_state\"] =  self.flow_belief_flat\n",
    "            agent[\"QDIFF_bayes_PGO\"] =  self.flow_theta_flat\n",
    "            agent[\"QDIFF_to_state\"] = self.net_belief_flat\n",
    "            agent[\"QDIFF_to_PGO\"] = self.net_theta_flat\n",
    "            agent[\"QDIFF_safe\"] = self.PSAFE_flat\n",
    "            agent[\"QDIFF_input\"] = self.input_flat[1]\n",
    "            agent[\"QDIFF_PGO\"] = self.PGO_flat\n",
    "            agent[\"QDIFF_to_DV_est_mu\"] = self.net_DV_est_mus \n",
    "\n",
    "        \"\"\" change here \"\"\"\n",
    "        # default network names\n",
    "        trained_net = 'LSTM_neg'\n",
    "        readout_net = 'LSTM_readout_neg' \n",
    "        readout_ctx_net =  'LSTM_readout_ctx_neg'\n",
    "        batches = 1\n",
    "        N = 100\n",
    "        \"\"\" change here \"\"\"\n",
    "\n",
    "        # Bayes with optimal policy data plus trained net \n",
    "        prefix = trained_net + \"_0\"\n",
    "        subnets = \"bayes_optim\"  \n",
    "        self = gen_data(prefix, subnets, N, use_mini_eps = False)\n",
    "        agent_name = \"bayes_agent_and_trained_LSTM_representation\"\n",
    "        plotting_data[agent_name] = dict()\n",
    "        agent = plotting_data[agent_name]\n",
    "        postprocess_bayes(self, agent)\n",
    "                               \n",
    "        # # Bayes with optimal policy data plus random net \n",
    "        prefix = readout_net + \"_0\"\n",
    "        subnets = \"bayes_optim\"\n",
    "        self = gen_data(prefix, subnets, N)   \n",
    "        agent_name = \"bayes_agent_and_random_LSTM_representation\"\n",
    "        plotting_data[agent_name] = dict()\n",
    "        agent = plotting_data[agent_name] \n",
    "        postprocess_bayes(self, agent)\n",
    "\n",
    "        # # Bayes with optimal policy data plus random net + context\n",
    "        prefix = readout_ctx_net + \"_0\"\n",
    "        subnets = \"bayes_optim\"\n",
    "        self = gen_data(prefix, subnets, N, give_ctx = True)    \n",
    "\n",
    "        agent_name = \"bayes_agent_and_random_LSTM_plus_ctx_representation\"\n",
    "        plotting_data[agent_name] = dict()\n",
    "        agent = plotting_data[agent_name]\n",
    "        postprocess_bayes(self, agent)\n",
    "\n",
    "        for i in range(batches):\n",
    "            print(f\"\\nCOLLECTING DATA\\nFOR NETWORK {i+1}/{batches} \\n\")\n",
    "            suffix = f\"_{i}\"\n",
    "            subnets = None       \n",
    "            mini = i > 0\n",
    "            # # trained network \n",
    "            print(\"TRAINED ARGMAX\")\n",
    "            self = gen_data(trained_net + suffix, subnets, N, argmax = True, use_mini_eps = mini)        \n",
    "            postprocess_networks(self, \"trained_LSTM\", i, plotting_data)\n",
    "            # # trained network softmax\n",
    "            print(\"TRAINED SOFTMAX\")\n",
    "            self = gen_data(trained_net + suffix, subnets, N, use_mini_eps = mini)       \n",
    "            postprocess_networks(self, \"trained_LSTM_soft\", i, plotting_data)\n",
    "            # # readout network \n",
    "            print(\"READOUT\")\n",
    "            self = gen_data(readout_net + suffix, subnets, N, use_mini_eps = mini)    \n",
    "            postprocess_networks(self, \"random_LSTM\", i, plotting_data)\n",
    "            # # readout network + ctx         \n",
    "            print(\"READOUT PLUS CTX\")\n",
    "            self = gen_data(readout_ctx_net + suffix, subnets, N, give_ctx = True, use_mini_eps = mini)        \n",
    "            postprocess_networks(self, \"random_LSTM_plus_ctx\", i, plotting_data)\n",
    "\n",
    "        # # trained network \n",
    "        plant_A = [0,1,0,1,0,0,0,0]\n",
    "        plant_B = [0,1,1,1,1,0,0,1]\n",
    "        PGO = [.2, .5, .8]\n",
    "        plant = np.array([plant_A, plant_B])\n",
    "        self = gen_data(trained_net + \"_0\", subnets, N, use_mini_eps = False, plant = plant, plant_prob = .1, PGOs = PGO)        \n",
    "        agent_name = \"trained_LSTM_planted\"\n",
    "        plotting_data[agent_name] = dict()\n",
    "        agent = plotting_data[agent_name]\n",
    "        append_common_fields(self, agent)\n",
    "        self.run_regressions(regress_to = 'ground_truth', regress_from = 'STM', get = True)\n",
    "        self.get_indices(planted = True, plant_ID = 0, eps_init = 0, full_prep = True, align_on = \"onset\", til_action = True)        \n",
    "        agent[\"plantA_GOs\"] =  self.GO_mus \n",
    "        agent[\"plantA_bayes_safe_est\"] = self.flow_belief_mus\n",
    "        agent[\"plantA_net_safe_est\"] = self.net_belief_mus\n",
    "        self.get_indices(planted = True, plant_ID = 1, eps_init = 0, full_prep = True, align_on = \"onset\", til_action = True)        \n",
    "        agent[\"plantB_GOs\"] =  self.GO_mus \n",
    "        agent[\"plantB_bayes_safe_est\"] = self.flow_belief_mus\n",
    "        agent[\"plantB_net_safe_est\"] = self.net_belief_mus\n",
    "        agent[\"plantA_seq\"] = plant_A\n",
    "        agent[\"plantB_seq\"] = plant_B\n",
    "\n",
    "        self.run_regressions(regress_to = 'ground_truth', regress_from = 'PCA', get = True)\n",
    "        self.get_indices(planted = True, plant_ID = 0, eps_init = 0, full_prep = True, align_on = \"onset\", til_action = True)        \n",
    "        agent[\"PC_plantA_net_safe_est\"] = self.net_belief_mus\n",
    "        self.get_indices(planted = True, plant_ID = 1, eps_init = 0, full_prep = True, align_on = \"onset\", til_action = True)        \n",
    "        agent[\"PC_plantB_net_safe_est\"] = self.net_belief_mus\n",
    "        del(self)\n",
    "        \n",
    "        # save as a big pickle file\n",
    "        with open(path, 'wb') as d:\n",
    "            pickle.dump(plotting_data, d, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        save_pytree(plotting_data, path)\n",
    "\n",
    "    return plotting_data\n",
    "a = get_data(name = \"north_test\", eps = 8000, mini_eps = 200)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
